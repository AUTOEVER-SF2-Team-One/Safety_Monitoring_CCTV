from flask import Flask, render_template, Response, request
import cv2
import numpy as np
from collections import deque
import joblib
from get_pose_landmark_yolo import get_yolo_landmarks_from_image, initialize_yolo_model
from ultralytics import YOLO
from typing import List
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# XGBoost ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def load_pose_model(model_path: str):
    try:
        print(f"XGBoost ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤... (ê²½ë¡œ: {model_path})")
        model = joblib.load(model_path)
        print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return model
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# í¬ì¦ˆ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_pose(model, landmarks: List) -> int:
    try:
        if len(landmarks) != 17:
            print(f"ì˜¤ë¥˜: ëœë“œë§ˆí¬ ê°œìˆ˜ê°€ 17ê°œê°€ ì•„ë‹™ë‹ˆë‹¤ (í˜„ì¬: {len(landmarks)}ê°œ).")
            return -1
        feature_vector = np.array(landmarks).flatten()
        feature_vector_2d = feature_vector.reshape(1, -1)
        prediction = model.predict(feature_vector_2d)
        return prediction[0]
    except Exception as e:
        print(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return -1

# ë„˜ì–´ì§ ìƒíƒœ ê°ì§€ í•¨ìˆ˜
def run(fall_classifier_model, landmark_data: List) -> bool:
    FALLEN_CLASS_ID = 1
    if not landmark_data:
        return False
    for person_landmarks in landmark_data:
        predicted_class = predict_pose(fall_classifier_model, person_landmarks)
        if predicted_class == -1:
            continue
        if predicted_class == FALLEN_CLASS_ID:
            return True
    return False

# ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
def process_video():
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("ğŸš¨ ì˜¤ë¥˜: ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    classifier_model_path = 'yolo/xgb_yolo_model.joblib'
    pose_detector = initialize_yolo_model()
    fall_classifier = load_pose_model(classifier_model_path)

    if not all([pose_detector, fall_classifier]):
        print("â›”ï¸ ëª¨ë¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í•˜ì—¬ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    WINDOW_SIZE = 150  # ìµœê·¼ 150ê°œ í”„ë ˆì„ì„ ê¸°ì–µ
    FALL_THRESHOLD_RATIO = 0.9  # ìœˆë„ìš°ì˜ 70% ì´ìƒì´ 'ë„˜ì–´ì§'ì¼ ë•Œ ìµœì¢… íŒë‹¨
    FALL_THRESHOLD = int(WINDOW_SIZE * FALL_THRESHOLD_RATIO)
    detection_history = deque(maxlen=WINDOW_SIZE)
    is_fall_confirmed = False  # ìµœì¢… ë„˜ì–´ì§ íŒë‹¨ ìƒíƒœ

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # 1. YOLO ëª¨ë¸ë¡œ í¬ì¦ˆ ì¶”ì •
        results = pose_detector(frame, verbose=False, conf=0.7)
        annotated_frame = results[0].plot()

        # 2. ëœë“œë§ˆí¬ ë°ì´í„° ì¶”ì¶œ
        landmark_data = []
        if results[0].keypoints and len(results[0].keypoints.xy) > 0:
            for kps in results[0].keypoints:
                person_landmarks = []
                coords = kps.xyn[0]
                confs = kps.conf[0]
                for i in range(len(coords)):
                    person_landmarks.append((coords[i][0].item(), coords[i][1].item(), confs[i].item()))
                landmark_data.append(person_landmarks)

        # 3. í˜„ì¬ í”„ë ˆì„ì˜ ë„˜ì–´ì§ ì—¬ë¶€ íŒë‹¨
        is_fallen_current_frame = run(fall_classifier, landmark_data)

        # 4. í˜„ì¬ í”„ë ˆì„ì˜ ê²°ê³¼ë¥¼ detection_historyì— ì¶”ê°€
        detection_history.append(is_fallen_current_frame)

        # 5. ìœˆë„ìš° ë‚´ 'ë„˜ì–´ì§' íƒì§€ íšŸìˆ˜ ê³„ì‚°
        fall_count_in_window = sum(detection_history)

        # 6. ìµœì¢… ë„˜ì–´ì§ ìƒíƒœ íŒë‹¨
        if fall_count_in_window >= FALL_THRESHOLD:
            is_fall_confirmed = True
            print(f"ë„˜ì–´ì§ ê°ì§€! (ìµœê·¼ {WINDOW_SIZE}ê°œ í”„ë ˆì„ ì¤‘ {fall_count_in_window}ë²ˆ ê°ì§€)")
        elif fall_count_in_window == 0:
            is_fall_confirmed = False
        
        # 7. ìµœì¢… íŒë‹¨ ê²°ê³¼ì— ë”°ë¼ í…ìŠ¤íŠ¸ í‘œì‹œ
        if is_fall_confirmed:
            cv2.putText(annotated_frame, "FALL DETECTED", (50, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA)

        # 8. ê²°ê³¼ë¥¼ í™”ë©´ì— ë³´ì—¬ì£¼ê¸°
        ret, buffer = cv2.imencode('.jpg', annotated_frame)
        frame_bytes = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

@app.route('/')
def index():
    return render_template('pose.html')

@app.route('/video_feed')
def video_feed():
    return Response(process_video(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/save_users', methods=['POST'])
def save_users():
    global userd
    data = request.json
    userd = data.get('users', [])
    return {"message": "User list updated."}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5002)
