import sys
sys.path.append('c:\\users\\í•œêµ­ì „íŒŒì§„í¥í˜‘íšŒ\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages')

from datetime import datetime
from flask import Flask, render_template, Response, request
import pymysql
from flask_cors import CORS
import cv2
import numpy as np
from ultralytics import YOLO
from flask_socketio import SocketIO, emit
from sort.sort import Sort  # SORT ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
from PIL import Image, ImageDraw, ImageFont
from yolo.get_pose_landmark_yolo import get_yolo_landmarks_from_image, initialize_yolo_model
from collections import deque
import joblib
from typing import List
import time  # ì‹œê°„ ì¸¡ì •ìš©
import winsound
import os

trr = [0, 0, 0, 0]
# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = Flask(__name__)
CORS(app)  # CORS í—ˆìš© (í¬ë¡œìŠ¤ ë„ë©”ì¸ ìš”ì²­ í—ˆìš©)
socketio = SocketIO(app)  # Flaskì™€ í•¨ê»˜ SocketIO ê°ì²´ ìƒì„±

font_path = "C:\\Users\\í•œêµ­ì „íŒŒì§„í¥í˜‘íšŒ\\Desktop\\java\\ìƒˆ í´ë” (2)\\Safety_Monitoring_CCTV-main\\Safety_Monitoring_CCTV-main\\body\\NanumGothic.ttf"  # í°íŠ¸ íŒŒì¼ ê²½ë¡œ (ì„œë²„ì— í•´ë‹¹ í°íŠ¸ê°€ ìˆì–´ì•¼ í•¨)
font = ImageFont.truetype(font_path, 20)  # í°íŠ¸ í¬ê¸° 20ìœ¼ë¡œ ì„¤ì •
#dbê³„ì • ì—°ê²°
db = pymysql.connect(host='127.0.0.1', user='root', password='root', db='pleaseworkcompany', charset='utf8')
cursor = db.cursor()

#global
# hat_count = 0
no_hat_count = {}
previous_hat_status = {}
dic_hat_status = {}
no_hat_start_time = {}
hat_status = "No Hat"
danger_start_time = 0
fall_start_time = 0

#ì‚¬ê°í˜• ë°”ë‹¥ì˜ ì¤‘ì•™ ì¢Œí‘œ ë½‘ê¸°
def box_base_center(box): 
    x1, y1, x2, y2 = box   # ê°ì²´ ì¶”ì ëœ (ì‚¬ëŒ,ì§€ê²Œì°¨) ì¢Œí‘œ
    cx = (x1 + x2) // 2    # xì¶• ì¤‘ì•™ (ì‚¬ê°í˜•ì˜ ê°€ë¡œ ì¤‘ì‹¬)
    cy = y2                # yì¶• í•˜ë‹¨ ì¢Œí‘œ (ë°”ë‹¥)
    return np.array([cx, cy]) # ì‚¬ê°í˜•ì˜ ë°”ë‹¥ ì¤‘ì•™ ì¢Œí‘œ

# - ë‘ ì  ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬(ì§ì„  ê±°ë¦¬)ë¥¼ ê³„ì‚°
def euclidean_distance(p1, p2):
    return np.linalg.norm(p1 - p2) # ë‘ ì  ê°„ ê±°ë¦¬ ê³„ì‚°
# ëª¨ì ì°©ìš© ìœ ë¬´ íŒë‹¨
def is_hat_in_person(person_box, hat_box, threshold=0.5):
    px1, py1, px2, py2 = person_box
    hx1, hy1, hx2, hy2 = hat_box
    trr[0] = hx1
    trr[1] = hy1
    trr[2] = hx2
    trr[3] = hy2
    # ëª¨ì ë°•ìŠ¤ ì•„ë˜ìª½(y2)ì´ ì‚¬ëŒ ë°•ìŠ¤ ìœ„ìª½(y1)ë³´ë‹¤ ë„ˆë¬´ ì•„ë˜ì— ìˆìœ¼ë©´ False
    person_height = py2 - py1
    if hy2 > py1 + person_height * 0.3:
        return False

    inter_x1 = max(px1, hx1)
    inter_y1 = max(py1, hy1)
    inter_x2 = min(px2, hx2)
    inter_y2 = min(py2, hy2)
    # ì‚¬ëŒ ë°•ìŠ¤ì™€ ëª¨ì ë°•ìŠ¤ ì‚¬ì´ì˜ ê²¹ì¹˜ëŠ” ì˜ì—­
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    # ëª¨ì ì˜ì—­
    hat_area = (hx2 - hx1) * (hy2 - hy1)
    if hat_area == 0:
        return False

    # ê²¹ì¹¨ ë¹„ìœ¨ê³¼ ì„ê³„ê°’ì— ë”°ë¼ ëª¨ì ì°©ìš© ìœ ë¬´ íŒë‹¨
    ratio = inter_area / hat_area
    return ratio > threshold

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
person_model = YOLO('C:\\Users\\í•œêµ­ì „íŒŒì§„í¥í˜‘íšŒ\\Desktop\\java\\ìƒˆ í´ë” (2)\\Safety_Monitoring_CCTV-main\\Safety_Monitoring_CCTV-main\\body\\person_model_yolov8m.pt')
hat_model = YOLO("C:\\Users\\í•œêµ­ì „íŒŒì§„í¥í˜‘íšŒ\\Desktop\\java\\ìƒˆ í´ë” (2)\\Safety_Monitoring_CCTV-main\\Safety_Monitoring_CCTV-main\\body\\hat_model_v1.pt")

tracker = Sort()

#cctv Cam
cap = cv2.VideoCapture(0)

# ì˜ì ì‹¤ì œ ë†’ì´ (m)ì™€ ì´ˆì  ê±°ë¦¬(í”½ì…€)
REAL_CHAIR_HEIGHT = 1.0
FOCAL_LENGTH_PIXELS = 700
K_chair = REAL_CHAIR_HEIGHT * FOCAL_LENGTH_PIXELS

# ì‹¤í—˜ì  ë³´ì • ê³„ìˆ˜ (ì‹¤ì œ ê±°ë¦¬ì™€ ì˜ìƒ ê±°ë¦¬ ì°¨ì´ ë³´ì •ìš©)
SCALE_FACTOR = 0.4  # í•„ìš”ì— ë”°ë¼ ì¡°ì •í•˜ì„¸ìš”

WARNING_DISTANCE = 200  # í”½ì…€ ê¸°ì¤€ ê²½ê³  ì„ê³„ê°’
output_width = 800
output_height = 600
paused = False

userd = []  # ì‚¬ìš©ìì˜ ì´ë¦„ ëª©ë¡
track_id_to_name = {}  # ê°ì²´ ì¶”ì  IDì™€ ì´ë¦„ì„ ë§¤í•‘í•  ë”•ì…”ë„ˆë¦¬
disappeared_names = []  # ì‚¬ë¼ì§„ ì‚¬ìš©ì ëª©ë¡

#ì´ë¦„ ë§¤ì¹­
def map_ids_to_names(detected_ids):
    global track_id_to_name, disappeared_names, userd
    current_ids = set(detected_ids)  # í˜„ì¬ ê°ì§€ëœ ID ì„¸íŠ¸
    tracked_ids = set(track_id_to_name.keys())  # ì´ì „ì— ì¶”ì ëœ ID ì„¸íŠ¸

    disappeared_ids = tracked_ids - current_ids  # ì‚¬ë¼ì§„ IDë“¤
    for did in disappeared_ids:
        name = track_id_to_name.pop(did, None)  # ì‚¬ë¼ì§„ IDì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ ì œê±°
        if name and name in userd:
            disappeared_names.append(name)  # ì‚¬ë¼ì§„ ì‚¬ìš©ì ëª©ë¡ì— ì¶”ê°€

    new_ids = current_ids - tracked_ids  # ìƒˆë¡œ ê°ì§€ëœ IDë“¤
    assigned_names = set(track_id_to_name.values())  # ì´ë¯¸ í• ë‹¹ëœ ì´ë¦„ë“¤
    available_names = disappeared_names.copy()  # ì‚¬ë¼ì§„ ì‚¬ìš©ì ëª©ë¡ì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©

    # ì•„ì§ í• ë‹¹ë˜ì§€ ì•Šì€ ì´ë¦„ì„ available_namesì— ì¶”ê°€
    for name in userd:
        if name not in assigned_names and name not in available_names:
            available_names.append(name)

    # ìƒˆë¡œ ê°ì§€ëœ IDì— ì´ë¦„ì„ í• ë‹¹
    for track_id in new_ids:
        if available_names:
            assigned_name = available_names.pop(0)  # ê°€ëŠ¥í•œ ì´ë¦„ì„ í•˜ë‚˜ í• ë‹¹
            track_id_to_name[track_id] = assigned_name
            if assigned_name in disappeared_names:
                disappeared_names.remove(assigned_name)  # ì‚¬ë¼ì§„ ëª©ë¡ì—ì„œ ì´ë¦„ ì œê±°
        else:
            track_id_to_name[track_id] = f"ì‚¬ëŒ{track_id}"  # ì´ë¦„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ "ì‚¬ëŒ{ID}"ë¡œ ì§€ì •

    return {tid: track_id_to_name[tid] for tid in detected_ids}

# WebSocket ì´ë²¤íŠ¸ ì²˜ë¦¬
@socketio.on('connect')
def handle_connect():
    print('Client connected')

@socketio.on('disconnect')
def handle_disconnect():
    print('Client disconnected')

# WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë²Œì  ë³´ë‚´ê¸°
def send_penalty():
    global no_hat_count
    socketio.emit('penalty_update', no_hat_count)  # WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë²Œì  ë°ì´í„° ì „ì†¡

# CCTV ì˜ìƒ ì²˜ë¦¬ í•¨ìˆ˜
def process_video():
    global danger_start_time
    global fall_start_time
    while cap.isOpened():
        ISFALL = 0 #ë„˜ì–´ì§„ ì‚¬ëŒì´ ìˆëŠ”ì§€
        ISHAT = 0 #ëª¨ìë¥¼ ì•ˆì“´ ì‚¬ëŒì´ ìˆëŠ”ì§€
        ISDANGER = 0 #ìœ„í—˜ì§€ì—­ì— ìˆëŠ” ì‚¬ëŒì´ ìˆëŠ”ì§€
        if not paused:
            ret, frame = cap.read()
            if not ret:
                break
            frame_time = datetime.now().strftime("%Y%m%d%H%M%S.%d")[:-3]  # ë°€ë¦¬ì´ˆê¹Œì§€ ì¶œë ¥
            print(f"ğŸ“¸ Frame captured at: {frame_time}")
            # 1) ì‚¬ëŒ ê°ì§€
            person_results = person_model(frame, verbose=False, conf = 0.6)[0]
            person_boxes_conf = []
            for det in person_results.boxes:
                if int(det.cls[0]) == 0:
                    x1, y1, x2, y2 = map(int, det.xyxy[0])
                    conf = float(det.conf[0])
                    person_boxes_conf.append([x1, y1, x2, y2, conf])

            person_boxes_np = np.array(person_boxes_conf) if len(person_boxes_conf) > 0 else None
            # 2) ì‚¬ëŒ íŠ¸ë˜í‚¹
            if person_boxes_np is not None:
                tracks = tracker.update(person_boxes_np)
            else:
                tracks = []

            # 3) ëª¨ì ê°ì§€
            hat_results = hat_model(frame, verbose=False, conf = 0.4)[0]
            hat_boxes = []
            for det in hat_results.boxes:
                x1, y1, x2, y2 = map(int, det.xyxy[0])
                hat_boxes.append([x1, y1, x2, y2])

            # 4) ì˜ì ê°ì§€ (ì‚¬ëŒ ëª¨ë¸ì—ì„œ í´ë˜ìŠ¤ 56 = chair)
            chair_boxes = []
            for det in person_results.boxes:
                cls = int(det.cls[0])
                if cls == 56:
                    x1, y1, x2, y2 = map(int, det.xyxy[0])
                    chair_boxes.append([x1, y1, x2, y2])
            # 5) ë„˜ì–´ì§ ê°ì§€
            classifier_model_path = 'yolo/xgb_yolo_model.joblib'
            pose_detector = initialize_yolo_model()
            fall_classifier = load_pose_model(classifier_model_path)
            results = pose_detector(frame, verbose=False, conf=0.7)
            annotated_frame = results[0].plot()
            landmark_data = []
            if results[0].keypoints and len(results[0].keypoints.xy) > 0:
                for kps in results[0].keypoints:
                    person_landmarks = []
                    coords = kps.xyn[0]
                    confs = kps.conf[0]
                    for i in range(len(coords)):
                        person_landmarks.append((coords[i][0].item(), coords[i][1].item(), confs[i].item()))
                    landmark_data.append(person_landmarks)
            is_fallen_current_frame = run(fall_classifier, landmark_data)

             # ì´ì°½ì—´ : íŠ¸ë˜í‚¹ ì¶”ì 
            detected_track_ids = [int(track[4]) for track in tracks]  # íŠ¸ë˜í‚¹ëœ ê°ì²´ì˜ ID
            name_map = map_ids_to_names(detected_track_ids)  # IDì— í•´ë‹¹í•˜ëŠ” ì´ë¦„ ë§¤í•‘
            
            # OpenCVì—ì„œ Pillow ì´ë¯¸ì§€ë¡œ ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(frame_rgb)
            draw = ImageDraw.Draw(pil_img)
            
            global no_hat_count, hat_status, previous_hat_status, dic_hat_status

            # tracksì™€ ê´€ë ¨ëœ ê° ì‚¬ëŒì˜ ëª¨ì ìƒíƒœë¥¼ ì¶”ì 
            for track in tracks:
                x1, y1, x2, y2, track_id = map(int, track)
                name = name_map.get(track_id, f"ID{track_id}")
                person_box = [x1, y1, x2, y2]

                # ëª¨ì ì°©ìš© ì—¬ë¶€ íŒë‹¨
                # ëª¨ì ì°©ìš© ì—¬ë¶€ íŒë‹¨
                hat_status = "No Hat"
                # dic_hat_status[name] = "No Hat" 
                for hat in hat_boxes:
                    if is_hat_in_person(person_box, hat, threshold=0.5):
                        hat_status = "Hat"
                        dic_hat_status[name] = "Hat"
                        break

                # ëª¨ì ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒ ì§€ì •
                color = (0, 255, 0) if hat_status == "Hat" else (0, 255, 255)  # ì´ˆë¡=ëª¨ì ìˆìŒ, ë…¸ë‘=ì—†ìŒ
                label_text = f"{name}: {hat_status}"
                
                 # `no_hat_count`ì— í•´ë‹¹ ì´ë¦„ì´ ì—†ë‹¤ë©´ ì´ˆê¸°í™”
                if name not in no_hat_count:
                    no_hat_count[name] = 0  # ê°’ì´ ì—†ì„ ë•Œë§Œ 0ìœ¼ë¡œ ì´ˆê¸°í™”

                # `previous_hat_status` ê°’ì´ ì—†ì„ ë•Œ ì´ˆê¸°í™”
                if name not in previous_hat_status:
                    previous_hat_status[name] = "No Hat"
                    
                if name not in no_hat_start_time:
                    no_hat_start_time[name] = None
                
                if hat_status == "No Hat":
                    # ëª¨ì ë²—ê¸° ì‹œì‘í•œ ì‹œê°„ì„ ê¸°ë¡
                    if no_hat_start_time[name] is None:
                        no_hat_start_time[name] = time.time()
                    else:
                        elapsed = time.time() - no_hat_start_time[name]
                        if elapsed >= 3.0:  # â±ï¸ 1ì´ˆ ì´ìƒ ìœ ì§€
                            no_hat_count[name] += 1
                            print(f"{name} ë²Œì  ì¦ê°€ â• {no_hat_count[name]}")
                            send_penalty()
                            no_hat_start_time[name] = None  # ë²Œì  ì¶”ê°€ í›„ ì´ˆê¸°í™”
                            ISHAT = 1 #dbì— ì €ì¥ìš©

                else:
                    # ëª¨ìë¥¼ ì“°ë©´ ì´ˆê¸°í™”
                    no_hat_start_time[name] = None
                    
                previous_hat_status[name] = hat_status
                
                # ìƒíƒœ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                print(f"No Hat Count: {no_hat_count[name]},{name}")

                # ì‚¬ëŒ ë°•ìŠ¤ ë° ëª¨ì ìƒíƒœ ì¶œë ¥
                
                # 0.6, color, 2)

                p_base = box_base_center(person_box)

                for c_box in chair_boxes:
                    c_base = box_base_center(c_box)
                    chair_height_px = c_box[3] - c_box[1]
                    if chair_height_px <= 0:
                        continue

                    # ì˜ì ë†’ì´ ê¸°ì¤€ ê±°ë¦¬ ê³„ì‚°
                    estimated_distance_m = K_chair / chair_height_px
                    dist_px = euclidean_distance(p_base, c_base)
                    real_distance_m = (dist_px / chair_height_px) * estimated_distance_m * SCALE_FACTOR

                    # ê±°ë¦¬ í‘œì‹œ
                    mid_x = (p_base[0] + c_base[0]) // 2
                    mid_y = (p_base[1] + c_base[1]) // 2
                    
                    
                    # 200í”½ì…€ ê¸°ì¤€(WARNING_DISTANCE) ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ ë³€í™”
                    distance_color = (255, 0, 0) if dist_px < WARNING_DISTANCE else (255, 255, 0)
                    
                    
                    draw.text((x1, y1 - 10), label_text, font=font, fill=distance_color)

                    draw.line([tuple(p_base), tuple(c_base)], fill=(255, 255, 0), width=2)


                    if dist_px < WARNING_DISTANCE:
                        if danger_start_time == 0:
                            danger_start_time = time.time()
                        else:
                            elapsed = time.time() - danger_start_time
                            if elapsed > 3.0:
                                ISDANGER = 1 #dbì— ì €ì¥ìš©
                        # ì‚¬ëŒ ë°•ìŠ¤ ê°•ì¡°
                        draw.rectangle([ (x1, y1), (x2, y2) ], outline=(0, 255, 0), width=3)

                        # ì˜ì ë°•ìŠ¤ ê°•ì¡°
                        draw.rectangle([ (c_box[0], c_box[1]), (c_box[2], c_box[3]) ], outline=(0, 0, 255), width=3)
                        global trr
                        draw.rectangle([ (trr[0], trr[1]), (trr[2], trr[3]) ], outline=(0, 255, 255), width=3)
                    else: #ë©€ì–´ì§€ë©´ ì´ˆê¸°í™”
                        danger_start_time = 0
            if is_fallen_current_frame:
                if fall_start_time == 0:
                        fall_start_time = time.time()
                else:
                    elapsed = time.time() - fall_start_time
                    if elapsed >= 3.0:  # â±ï¸ 1ì´ˆ ì´ìƒ ìœ ì§€
                        ISFALL = 1 #dbì— ì €ì¥ìš©
            else:
                fall_start_time = 0
        #ê¸°ë¡ ë‚ ì§œ ì €ì¥ìš©
        now = datetime.now()
        now_date = now.strftime("%Y-%m-%d")
        output_folder = f'accident_{now_date}'
        os.makedirs(output_folder, exist_ok=True)
        if ISFALL:
            # í˜„ì¬ í´ë” ì•ˆì˜ íŒŒì¼ ê°œìˆ˜ í™•ì¸
            existing_files = os.listdir(output_folder)
            next_index = len(existing_files) + 1
            filename = f'fall_{next_index}.jpg'
            frame_filename = os.path.join(output_folder, filename)
            photopath = os.path.join(output_folder, filename)
            cv2.imwrite(frame_filename, frame)
            sql = f"INSERT INTO `pleaseworkcompany`.`accident_log` (`ACCIDENTID`, `ACCIDENTDATE`, `LOGISDELETE`, `LOG_UPLOAD_DATE`, `LOG_PHOTO_PATH`) VALUES ('1', '{now_date}', '0', '{now_date}', '{filename}');"
            cursor.execute(sql)
            db.commit()
        if ISHAT:
            # í˜„ì¬ í´ë” ì•ˆì˜ íŒŒì¼ ê°œìˆ˜ í™•ì¸
            existing_files = os.listdir(output_folder)
            next_index = len(existing_files) + 1
            filename = f'not_hat_{next_index}.jpg'
            frame_filename = os.path.join(output_folder, filename)
            photopath = os.path.join(output_folder, filename)
            cv2.imwrite(frame_filename, frame)
            sql = f"INSERT INTO `pleaseworkcompany`.`accident_log` (`ACCIDENTID`, `ACCIDENTDATE`, `LOGISDELETE`, `LOG_UPLOAD_DATE`, `LOG_PHOTO_PATH`) VALUES ('2', '{now_date}', '0', '{now_date}', '{filename}');"
            cursor.execute(sql)
            db.commit()
        if ISDANGER:
            # í˜„ì¬ í´ë” ì•ˆì˜ íŒŒì¼ ê°œìˆ˜ í™•ì¸
            existing_files = os.listdir(output_folder)
            next_index = len(existing_files) + 1
            filename = f'danger_{next_index}.jpg'
            frame_filename = os.path.join(output_folder, filename)
            photopath = os.path.join(output_folder, filename)
            cv2.imwrite(frame_filename, frame)
            sql = f"INSERT INTO `pleaseworkcompany`.`accident_log` (`ACCIDENTID`, `ACCIDENTDATE`, `LOGISDELETE`, `LOG_UPLOAD_DATE`, `LOG_PHOTO_PATH`) VALUES ('3', '{now_date}', '0', '{now_date}', '{filename}');"
            cursor.execute(sql)
            db.commit()
        #draw ì´ë¯¸ì§€ ì²˜ë¦¬
        frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

        
        frame_resized = cv2.resize(frame, (output_width, output_height))
        ret, buffer = cv2.imencode('.jpg', frame_resized)
        frame_bytes = buffer.tobytes()

        # HTTP multipart ìŠ¤íŠ¸ë¦¼ í˜•ì‹ìœ¼ë¡œ í”„ë ˆì„ ì „ì†¡
        yield (b'--frame\r\n'
            b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')


# ë©”ì¸ í˜ì´ì§€ ë Œë”ë§ (HTML íŒŒì¼ë¡œ CCTV í™”ë©´ í‘œì‹œ)
@app.route('/')
def index():
    return render_template('hyun.html')

@app.route('/get_penalty', methods=['GET'])
def get_penalty():
    return no_hat_count

# ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì—”ë“œí¬ì¸íŠ¸
@app.route('/cctv_feed')
def cctv_feed():
    return Response(process_video(), mimetype='multipart/x-mixed-replace; boundary=frame')

# ì‚¬ìš©ìì˜ ì´ë¦„ ëª©ë¡ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.route('/save_users', methods=['POST'])
def save_users():
    global userd
    data = request.json  # ìš”ì²­ì—ì„œ JSON ë°ì´í„° ë°›ê¸°
    userd = data.get('users', [])  # ì‚¬ìš©ì ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    return {"message": "User list updated."}  # ì‘ë‹µ ë°˜í™˜

#---------------------------pose model-----------------------------------


# XGBoost ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def load_pose_model(model_path: str):
    try:
        print(f"XGBoost ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤... (ê²½ë¡œ: {model_path})")
        model = joblib.load(model_path)
        print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        return model
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# í¬ì¦ˆ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_pose(model, landmarks: List) -> int:
    try:
        if len(landmarks) != 17:
            print(f"ì˜¤ë¥˜: ëœë“œë§ˆí¬ ê°œìˆ˜ê°€ 17ê°œê°€ ì•„ë‹™ë‹ˆë‹¤ (í˜„ì¬: {len(landmarks)}ê°œ).")
            return -1
        feature_vector = np.array(landmarks).flatten()
        feature_vector_2d = feature_vector.reshape(1, -1)
        prediction = model.predict(feature_vector_2d)
        return prediction[0]
    except Exception as e:
        print(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return -1

# ë„˜ì–´ì§ ìƒíƒœ ê°ì§€ í•¨ìˆ˜
def run(fall_classifier_model, landmark_data: List) -> bool:
    FALLEN_CLASS_ID = 1
    if not landmark_data:
        return False
    for person_landmarks in landmark_data:
        predicted_class = predict_pose(fall_classifier_model, person_landmarks)
        if predicted_class == -1:
            continue
        if predicted_class == FALLEN_CLASS_ID:
            return True
    return False

# ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
def pose_video():
    # cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("ğŸš¨ ì˜¤ë¥˜: ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    classifier_model_path = 'yolo/xgb_yolo_model.joblib'
    pose_detector = initialize_yolo_model()
    fall_classifier = load_pose_model(classifier_model_path)

    if not all([pose_detector, fall_classifier]):
        print("â›”ï¸ ëª¨ë¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í•˜ì—¬ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    WINDOW_SIZE = 100  # ìµœê·¼ 100ê°œ í”„ë ˆì„ì„ ê¸°ì–µ
    FALL_THRESHOLD_RATIO = 0.85  # ìœˆë„ìš°ì˜ 70% ì´ìƒì´ 'ë„˜ì–´ì§'ì¼ ë•Œ ìµœì¢… íŒë‹¨
    FALL_THRESHOLD = int(WINDOW_SIZE * FALL_THRESHOLD_RATIO)
    detection_history = deque(maxlen=WINDOW_SIZE)
    is_fall_confirmed = False  # ìµœì¢… ë„˜ì–´ì§ íŒë‹¨ ìƒíƒœ

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # 1. YOLO ëª¨ë¸ë¡œ í¬ì¦ˆ ì¶”ì •
        results = pose_detector(frame, verbose=False, conf=0.7)
        annotated_frame = results[0].plot()

        # 2. ëœë“œë§ˆí¬ ë°ì´í„° ì¶”ì¶œ
        landmark_data = []
        if results[0].keypoints and len(results[0].keypoints.xy) > 0:
            for kps in results[0].keypoints:
                person_landmarks = []
                coords = kps.xyn[0]
                confs = kps.conf[0]
                for i in range(len(coords)):
                    person_landmarks.append((coords[i][0].item(), coords[i][1].item(), confs[i].item()))
                landmark_data.append(person_landmarks)

        # 3. í˜„ì¬ í”„ë ˆì„ì˜ ë„˜ì–´ì§ ì—¬ë¶€ íŒë‹¨
        is_fallen_current_frame = run(fall_classifier, landmark_data)

        
        # 7. ìµœì¢… íŒë‹¨ ê²°ê³¼ì— ë”°ë¼ í…ìŠ¤íŠ¸ í‘œì‹œ
        if is_fall_confirmed:
            cv2.putText(annotated_frame, "FALL DETECTED", (50, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA)
            winsound.Beep(1000, 10)
            
        
        # 8. ê²°ê³¼ë¥¼ í™”ë©´ì— ë³´ì—¬ì£¼ê¸°
        ret, buffer = cv2.imencode('.jpg', annotated_frame)
        frame_bytes = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

# @app.route('/pose')
# def pose():
#     return render_template('pose.html')

@app.route('/video_feed')
def video_feed():
    return Response(pose_video(), mimetype='multipart/x-mixed-replace; boundary=frame')


# Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
if __name__ == '__main__':
    # ë¹„ë””ì˜¤ ì²˜ë¦¬ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ, FlaskëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    app.run(host='0.0.0.0', port=5001)
